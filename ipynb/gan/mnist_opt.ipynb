{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "#%config InlineBackend.figure_format = 'svg'\n",
    "#%config InlineBackend.figure_format = 'pdf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import kmod\n",
    "import kmod.glo as glo\n",
    "import kmod.plot as plot\n",
    "import kmod.kernel as kernel\n",
    "from kmod import util\n",
    "import kmod.ex.exutil as exutil\n",
    "from kmod import data\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import torch\n",
    "import torch.autograd\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "\n",
    "from torch import optim\n",
    "from torch import nn\n",
    "import kmod.gan_ume_opt as ganopt\n",
    "from kmod.gan_ume_opt import ume_power_criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# font options\n",
    "font = {\n",
    "    #'family' : 'normal',\n",
    "    #'weight' : 'bold',\n",
    "    'size'   : 18\n",
    "}\n",
    "\n",
    "plt.rc('font', **font)\n",
    "plt.rc('lines', linewidth=2)\n",
    "matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "matplotlib.rcParams['ps.fonttype'] = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set this to False to avoid using a GPU\n",
    "use_cuda = True and torch.cuda.is_available()\n",
    "# load option depends on whether GPU is used\n",
    "load_options = {} if use_cuda else {'map_location': lambda storage, loc: storage} \n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "default_type = torch.cuda.FloatTensor if use_cuda else torch.FloatTensor\n",
    "torch.set_default_tensor_type(torch.cuda.FloatTensor if use_cuda else torch.FloatTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 13\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load feature extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load a model from the shared folder\n",
    "shared_resource_path = glo.shared_resource_folder()\n",
    "model_folder = glo.shared_resource_folder('prob_models', 'mnist_cnn')\n",
    "epochs = 20\n",
    "seed = 1\n",
    "model_fname = 'mnist_cnn_ep{}_s{}.pt'.format(epochs, seed)\n",
    "model_fpath = os.path.join(model_folder, model_fname)\n",
    "\n",
    "print('Shared resource path at: {}'.format(shared_resource_path))\n",
    "print('Model folder: {}'.format(model_folder))\n",
    "print('Model file: ', model_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from kmod.mnist.classify import MnistClassifier\n",
    "classifier = MnistClassifier.load(model_fpath, **load_options)\n",
    "# evaluation mode\n",
    "classifier = classifier.eval().to(device)\n",
    "# classifier is a torch.nn.Module\n",
    "display(classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractor(imgs):\n",
    "    \"\"\"\n",
    "    Feature extractor\n",
    "    \"\"\"\n",
    "    self = classifier\n",
    "    x = imgs\n",
    "    x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "    x = F.relu(F.max_pool2d(self.conv2(x), 2))\n",
    "    x = x.view(-1, 320)\n",
    "    return x\n",
    "\n",
    "def extractor_cls(imgs):\n",
    "    self = classifier\n",
    "    x = imgs\n",
    "    x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "    x = F.relu(F.max_pool2d(self.conv2(x), 2))\n",
    "    x = x.view(-1, 320)\n",
    "    x = F.relu(self.fc1(x))\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load models and generate samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these lines are necessary for loading DCGAN\n",
    "from kmod.mnist.dcgan import Generator\n",
    "from kmod.mnist.dcgan import DCGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type_p = 'lsgan'\n",
    "# model_type_p = 'dcgan'\n",
    "epoch = 20\n",
    "gen_p = exutil.load_mnist_gen(model_type_p, epoch, default_type, **load_options)\n",
    "model_name_p = '{}_{}'.format(model_type_p, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kmod.plot as plot\n",
    "\n",
    "# generate images and show\n",
    "n_gen = 20*5\n",
    "gen_imgs = gen_p.sample(n_gen)\n",
    "\n",
    "plt.figure(figsize=(20, 5))\n",
    "plot.show_torch_imgs(gen_imgs, nrow=20, figsize=(20, 5), normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type_q = 'dcgan'\n",
    "epoch = 50\n",
    "gen_q = exutil.load_mnist_gen(model_type_q, epoch, default_type, **load_options)\n",
    "model_name_q = '{}_{}'.format(model_type_q, epoch)\n",
    "# print(gen_q.sample_noise(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import kmod.plot as plot\n",
    "\n",
    "# generate images and show\n",
    "n_gen = 20*5\n",
    "gen_imgs = gen_q.sample(n_gen)\n",
    "\n",
    "plt.figure(figsize=(20, 5))\n",
    "plot.show_torch_imgs(gen_imgs, nrow=20, figsize=(20, 5), normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load MNIST Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load MNIST data\n",
    "mnist_folder = glo.data_file('mnist')\n",
    "mnist_dataset = torchvision.datasets.MNIST(mnist_folder, train=False, \n",
    "                        transform=transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize((0.1307,), (0.3081,))\n",
    "                       ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_sample = 2000\n",
    "classes = 10\n",
    "n_sample_per_class = num_sample // classes\n",
    "len_data = len(mnist_dataset)\n",
    "input_Z = []\n",
    "mnist_Y = torch.stack([mnist_dataset[i][1] for i in range(len_data)])\n",
    "mnist_X = torch.stack([mnist_dataset[i][0] for i in range(len_data)])\n",
    "for i in range(classes):\n",
    "    idx_Y = mnist_Y[mnist_Y==i]\n",
    "    idx = util.subsample_ind(len(idx_Y), n_sample_per_class, seed=13)\n",
    "    input_Z.append(mnist_X[idx_Y][idx])\n",
    "#input_Z = [mnist_dataset[i][0] for i in range(num_sample)]\n",
    "input_Z = torch.cat(input_Z).to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample from generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm(x, loc, scale):\n",
    "    return (x - loc) / scale\n",
    "\n",
    "\n",
    "def mnist_norm(x):\n",
    "    return norm(x, 0.1307, 0.3081)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trans_gan(x):\n",
    "    y = norm(x, -1.0, 2.0)\n",
    "    return mnist_norm(y)\n",
    "\n",
    "\n",
    "def trans_vae(x):\n",
    "    return mnist_norm(x).view(-1, 1, 28, 28)\n",
    "\n",
    "def get_trans(model_type):\n",
    "    name = model_type.lower()\n",
    "    if name not in exutil.mnist_model_names:\n",
    "        raise ValueError('Model name has be one of '\n",
    "                          '{} and was'.format(key_list, name))\n",
    "    print('Model: {}'.format(name))\n",
    "    if 'gan' in name:\n",
    "        return trans_gan\n",
    "    elif name == 'vae':\n",
    "        return mnist_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "J = 10\n",
    "\n",
    "gen_p_forward = gen_p.module.forward\n",
    "gen_q_forward = gen_q.module.forward\n",
    "trans_p = get_trans(model_type_p)\n",
    "trans_q = get_trans(model_type_q)\n",
    "#featurizer = extractor_cls\n",
    "featurizer = classifier\n",
    "\n",
    "reg = 1e-4 \n",
    "lam_z = 1e-5\n",
    "lam_gw = 1e-4\n",
    "gwidth_lb = None\n",
    "gwidth_ub = None\n",
    "Zp_lb= -(4.**2)\n",
    "Zp_ub= 1.**2\n",
    "Zq_lb= -(4.**2)\n",
    "Zq_ub= 1.**2\n",
    "\n",
    "X = featurizer(trans_p(gen_p.sample(num_sample)))\n",
    "Y = featurizer(trans_q(gen_q.sample(num_sample)))\n",
    "Z = featurizer(input_Z)\n",
    "\n",
    "XYZ = np.vstack((X.cpu().data.numpy(), Y.cpu().data.numpy(), Z.cpu().data.numpy()))\n",
    "med = util.meddistance(XYZ, subsample=1000)\n",
    "gwidth0 = med\n",
    "Zp0 = torch.rand([J, gen_p.in_out_shapes[0]]) - 0.5\n",
    "Zq0 = torch.rand([J, gen_q.in_out_shapes[0]]) - 0.5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reg_z(Zp, Zq):\n",
    "    eps = 0.  # 1e-10\n",
    "    log_bar_p = (torch.sum(torch.log(Zp_ub-Zp**2+eps)) \n",
    "                 if Zp_ub is not None else 0)\n",
    "    # log_bar_p = (log_bar_p + torch.sum(torch.log(-Zp_lb+Zp+eps))\n",
    "                 # if Zp_lb is not None else log_bar_p)\n",
    "    log_bar_q = (torch.sum(torch.log(Zq_ub-Zq**2+eps)) \n",
    "                 if Zq_ub is not None else 0)\n",
    "    #log_bar_q = (log_bar_q + torch.sum(torch.log(-Zq_lb+Zq+eps))\n",
    "                 #if Zq_lb is not None else log_bar_q)\n",
    "    return log_bar_p + log_bar_q\n",
    "\n",
    "def reg_gw2(gwidth2):\n",
    "    eps = 0.  # 1e-6\n",
    "    log_bar_gwidth = (torch.log(gwidth_ub-gwidth2+eps)\n",
    "                      if gwidth_ub is not None else 0)\n",
    "    log_bar_gwidth = (log_bar_gwidth + (torch.log(-max(gwidth_lb, 0)+gwidth2+eps))\n",
    "                      if gwidth_lb is not None else log_bar_gwidth)\n",
    "\n",
    "    return log_bar_gwidth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = torch.float\n",
    "gwidth2 = torch.tensor(gwidth0**2, requires_grad=True, device=device)\n",
    "k = kernel.PTKGauss(gwidth2)\n",
    "Zp = torch.tensor(Zp0, requires_grad=True, device=device,\n",
    "        dtype=dtype)\n",
    "Zq = torch.tensor(Zq0, requires_grad=True, device=device,\n",
    "        dtype=dtype)\n",
    "\n",
    "X = torch.tensor(X, requires_grad=False, \n",
    "                 device=device, dtype=dtype)\n",
    "Y = torch.tensor(Y, requires_grad=False,\n",
    "                 device=device, dtype=dtype)\n",
    "Z = torch.tensor(Z, requires_grad=False,\n",
    "                 device=device, dtype=dtype)\n",
    "\n",
    "# optimizer = optim.LBFGS([gwidth2, Zp, Zq], lr=1e-3, max_iter=20)\n",
    "# optimizer = optim.SGD([gwidth2, Zp, Zq], lr=1e-3, momentum=0.9, nesterov=True)\n",
    "optimizer = optim.Adam([k.sigma2, Zp, Zq], lr=1e-3)\n",
    "# transform = nn.Upsample((model_input_size, model_input_size), mode='bilinear')\n",
    "\n",
    "num_steps = 500\n",
    "log_inter = 10\n",
    "\n",
    "run = [0]\n",
    "while run[0] <= num_steps:\n",
    "    \n",
    "    def closure():\n",
    "        optimizer.zero_grad()\n",
    "        im_p = gen_p_forward(Zp)\n",
    "        im_q = gen_q_forward(Zq)\n",
    "        Vp = featurizer(trans_p(im_p)) if trans_p is not None else featurizer(im_p)\n",
    "        Vq = featurizer(trans_q(im_q)) if trans_q is not None else featurizer(im_q)\n",
    "        V = torch.cat([Vp, Vq], dim=0)\n",
    "        #power = ume_power_criterion(X, Y, Z, Vp, Vq, k, reg)\n",
    "        power = ume_power_criterion(X, Y, Z, V, V, k, reg)\n",
    "        obj = -power  - lam_z*reg_z(Zp, Zq) - lam_gw*reg_gw2(k.sigma2)\n",
    "        obj.backward(retain_graph=True)\n",
    "        run[0] += 1\n",
    "        if run[0] % log_inter == 0:\n",
    "            print('run {}'.format(run))\n",
    "            print(obj, power)\n",
    "        return obj\n",
    "    optimizer.step(closure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_imgs = gen_p_forward(Zp)\n",
    "Vp = featurizer(trans_p(gen_imgs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "plot.show_torch_imgs(gen_imgs.detach(), nrow=8, figsize=(8, 5), normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gen_imgs = vae.decode(Zq).detach().view(-1, 1, 28, 28)\n",
    "gen_imgs = gen_q_forward(Zq).detach()\n",
    "Vq = featurizer(trans_q(gen_imgs))\n",
    "plt.figure(figsize=(8, 5))\n",
    "plot.show_torch_imgs(gen_imgs, nrow=8, figsize=(8, 5), normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Zp.max())\n",
    "print(Zp.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Zq.max())\n",
    "print(Zq.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(k.sigma2, gwidth0**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the power criterion value at each location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kmod import mctest \n",
    "from kgof import kernel as kgof_kernel\n",
    "V = torch.cat([Vp, Vq]).cpu().data.numpy()\n",
    "for j in range(J):\n",
    "    V = Vq[j].cpu().data.numpy().reshape([1, -1])\n",
    "    kg = kgof_kernel.KGauss(gwidth2.item())\n",
    "    datap = kmod.data.Data(X.cpu().data.numpy())\n",
    "    dataq = kmod.data.Data(Y.cpu().data.numpy())\n",
    "    datar = kmod.data.Data(Z.cpu().data.numpy())\n",
    "    sc_ume = mctest.SC_UME(datap, dataq, kg, kg, V, V)\n",
    "    print(j, sc_ume.compute_stat(datar))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discrete optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slice_array(arr, sizes):\n",
    "    if not sizes or sum(sizes) == 0 or len(sizes) == 0:\n",
    "        raise ValueError('sizes cannot be empty. Was {}'.format(sizes))\n",
    "    sub_arrs = []\n",
    "    idx = 0\n",
    "    for i in range(0, len(sizes)):\n",
    "        sub_arrs.append(arr[idx: idx+sizes[i]])\n",
    "        idx += sizes[i]\n",
    "    return sub_arrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "J = 30\n",
    "\n",
    "num_classes = 10\n",
    "trans_p = get_trans(model_type_p)\n",
    "trans_q = get_trans(model_type_q)\n",
    "featurizer = extractor_cls\n",
    "#featurizer = classifier\n",
    "\n",
    "reg = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Y = featurizer(mnist_norm(vae_sample(vae, num_sample)))\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "V_pool = []\n",
    "Z_list = []\n",
    "for j in range(num_classes):\n",
    "    idx = (mnist_Y == j)\n",
    "    rand_idx = util.subsample_ind(len(mnist_Y[idx]), len(mnist_Y[idx]), seed=seed)\n",
    "    Z, V = slice_array(mnist_X[idx][rand_idx], [n_sample_per_class, J]) \n",
    "    Z_list.append(Z)\n",
    "    V_pool.append(V)\n",
    "\n",
    "X = featurizer(trans_p(gen_p.sample(num_sample)))\n",
    "Y = featurizer(trans_q(gen_q.sample(num_sample)))\n",
    "Z = torch.cat(Z_list).to(device)\n",
    "Z = featurizer(Z)\n",
    "\n",
    "X = X.cpu().data.numpy()\n",
    "Y = Y.cpu().data.numpy()\n",
    "Z = Z.cpu().data.numpy()\n",
    "\n",
    "XYZ = np.vstack((X, Y, Z))\n",
    "med = util.meddistance(XYZ, subsample=1000)\n",
    "k = kernel.KGauss(med**2)\n",
    "\n",
    "V = torch.cat(V_pool)\n",
    "fV = featurizer(V.to(device)).cpu().data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with util.ContextTimer() as t:\n",
    "    opt_idx = ganopt.opt_greedy_3sample_criterion(data.Data(X), data.Data(Y), data.Data(Z), fV, k, J, maximize=True)\n",
    "print('Took {} secs'.format(t.secs))\n",
    "opt_locs = V[opt_idx]\n",
    "plot.show_torch_imgs(opt_locs, nrow=6, figsize=(6, 5), normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with util.ContextTimer() as t:\n",
    "    opt_idx = ganopt.opt_greedy_3sample_criterion(data.Data(X), data.Data(Y), data.Data(Z), fV, k, J, maximize=False)\n",
    "print('Took {} secs'.format(t.secs))\n",
    "opt_locs = V[opt_idx]\n",
    "plot.show_torch_imgs(opt_locs, nrow=6, figsize=(6, 5), normalize=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
