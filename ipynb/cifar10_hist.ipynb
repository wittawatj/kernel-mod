{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook to plot the histogram of the power criterion values of Rel-UME test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "#%config InlineBackend.figure_format = 'svg'\n",
    "#%config InlineBackend.figure_format = 'pdf'\n",
    "\n",
    "import freqopttest.tst as tst\n",
    "import kmod\n",
    "import kgof\n",
    "import kgof.goftest as gof\n",
    "# submodules\n",
    "from kmod import data, density, kernel, util, plot, glo, log\n",
    "from kmod.ex import cifar10 as cf10\n",
    "import kmod.ex.exutil as exu\n",
    "\n",
    "from kmod import mctest as mct\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import autograd.numpy as np\n",
    "import scipy.stats as stats\n",
    "import numpy.testing as testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot.set_default_matplotlib_options()\n",
    "# font options\n",
    "font = {\n",
    "    #'family' : 'normal',\n",
    "    #'weight' : 'bold',\n",
    "    'size'   : 20,\n",
    "}\n",
    "\n",
    "plt.rc('font', **font)\n",
    "plt.rc('lines', linewidth=2)\n",
    "matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "matplotlib.rcParams['ps.fonttype'] = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def store_path(fname):\n",
    "#     \"\"\"\n",
    "#     Construct a full path for saving/loading files.\n",
    "#     \"\"\"\n",
    "#     return os.path.join('cifar10', fname)\n",
    "display(list(zip(range(10), cf10.cifar10_classes)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Histogram of power criterion values\n",
    "\n",
    "First construct four samples: X~P, Y~Q, Z~R, and a pool W to be used as test location candidates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class_spec = [\n",
    "#     # (class, #points for p, #points for q, #points for r, #points for the pool)\n",
    "#     ('airplane', 2000, 0, 0, 1500),\n",
    "#     ('cat',      0, 2000, 2000, 1500),\n",
    "#     ('truck',    1500, 1500, 1500, 1500),\n",
    "    \n",
    "# ]\n",
    "\n",
    "class_spec = [\n",
    "    # (class, #points for p, #points for q, #points for r, #points for the pool)\n",
    "    ('airplane', 1000, 0, 0, 300),\n",
    "    ('cat',      0, 1000, 1000, 300),\n",
    "    ('truck',    1500, 1500, 1500, 300),\n",
    "    \n",
    "]\n",
    "\n",
    "# class_spec = [\n",
    "#     # (class, #points for p, #points for q, #points for r, #points for the pool)\n",
    "#     ('airplane', 200, 0, 0, 150),\n",
    "#     ('cat',      0, 200, 200, 150),\n",
    "#     ('truck',    150, 150, 150, 150),\n",
    "    \n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check sizes\n",
    "hist_classes = [z[0] for z in class_spec]\n",
    "p_sizes = [z[1] for z in class_spec]\n",
    "q_sizes = [z[2] for z in class_spec]\n",
    "r_sizes = [z[3] for z in class_spec]\n",
    "pool_sizes = [z[4] for z in class_spec]\n",
    "\n",
    "# make sure p,q,r have the same sample size\n",
    "assert sum(p_sizes) == sum(q_sizes)\n",
    "assert sum(q_sizes) == sum(r_sizes)\n",
    "\n",
    "# cannot use more than 6000 from each class\n",
    "for i, cs in enumerate(class_spec):\n",
    "    class_used = sum(cs[1:])\n",
    "    if class_used > 6000:\n",
    "        raise ValueError('class \"{}\" requires more than 6000 points. Was {}.'.format(cs[0], class_used))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# images as numpy arrays\n",
    "list_Ximgs = []\n",
    "list_Yimgs = []\n",
    "list_Zimgs = []\n",
    "list_poolimgs = []\n",
    "\n",
    "# features\n",
    "list_X = []\n",
    "list_Y = []\n",
    "list_Z = []\n",
    "list_pool = []\n",
    "# class labels\n",
    "list_Xlabels = []\n",
    "list_Ylabels = []\n",
    "list_Zlabels = []\n",
    "list_poollabels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed used for subsampling\n",
    "seed = 365\n",
    "with util.NumpySeedContext(seed=seed):\n",
    "    for i, cs in enumerate(class_spec):\n",
    "        # load class data\n",
    "        class_i = cs[0]\n",
    "        imgs_i = cf10.load_data_array(class_i)\n",
    "        feas_i = cf10.load_feature_array(class_i)\n",
    "\n",
    "        # split each class according to the spec\n",
    "        class_sizes_i = cs[1:]\n",
    "        # imgs_i, feas_i may contain more than what we need in total for a class. Subsample\n",
    "        sub_ind = util.subsample_ind(imgs_i.shape[0], sum(class_sizes_i))\n",
    "        sub_ind = list(sub_ind)\n",
    "        assert len(sub_ind) == sum(class_sizes_i)\n",
    "        \n",
    "        xyzp_imgs_i = util.multi_way_split(imgs_i[sub_ind,:], class_sizes_i)\n",
    "        xyzp_feas_i = util.multi_way_split(feas_i[sub_ind,:], class_sizes_i)\n",
    "        \n",
    "        # assignment\n",
    "        list_Ximgs.append(xyzp_imgs_i[0])\n",
    "        list_Yimgs.append(xyzp_imgs_i[1])\n",
    "        list_Zimgs.append(xyzp_imgs_i[2])\n",
    "        list_poolimgs.append(xyzp_imgs_i[3])\n",
    "        \n",
    "        list_X.append(xyzp_feas_i[0])\n",
    "        list_Y.append(xyzp_feas_i[1])\n",
    "        list_Z.append(xyzp_feas_i[2])\n",
    "        list_pool.append(xyzp_feas_i[3])\n",
    "        \n",
    "        # class labels\n",
    "        class_ind_i = cf10.cifar10_class_ind_dict[class_i]\n",
    "        list_Xlabels.append(np.ones(class_sizes_i[0])*class_ind_i)\n",
    "        list_Ylabels.append(np.ones(class_sizes_i[1])*class_ind_i)\n",
    "        list_Zlabels.append(np.ones(class_sizes_i[2])*class_ind_i)\n",
    "        list_poollabels.append(np.ones(class_sizes_i[3])*class_ind_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we have the samples (features and images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stack the lists. For the \"hisogram\" purpose, we don't actually need\n",
    "# images for X, Y, Z. Only images for the pool.\n",
    "Ximgs = np.vstack(list_Ximgs)\n",
    "Yimgs = np.vstack(list_Yimgs)\n",
    "Zimgs = np.vstack(list_Zimgs)\n",
    "poolimgs = np.vstack(list_poolimgs)\n",
    "\n",
    "# features\n",
    "X = np.vstack(list_X)\n",
    "Y = np.vstack(list_Y)\n",
    "Z = np.vstack(list_Z)\n",
    "pool = np.vstack(list_pool)\n",
    "\n",
    "# labels\n",
    "Xlabels = np.hstack(list_Xlabels)\n",
    "Ylabels = np.hstack(list_Ylabels)\n",
    "Zlabels = np.hstack(list_Zlabels)\n",
    "poollabels = np.hstack(list_poollabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check\n",
    "XYZP = [(X, Ximgs, Xlabels), (Y, Yimgs, Ylabels), (Z, Zimgs, Zlabels), (pool, poolimgs, poollabels)]\n",
    "for f, fimgs, flabels in XYZP:\n",
    "    assert f.shape[0] == fimgs.shape[0]\n",
    "    assert fimgs.shape[0] == flabels.shape[0]\n",
    "assert X.shape[0] == sum(p_sizes)\n",
    "assert Y.shape[0] == sum(q_sizes)\n",
    "assert Z.shape[0] == sum(r_sizes)\n",
    "assert pool.shape[0] == sum(pool_sizes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The actual histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_test_locations(X, Y, Z, loc_pool, k, func_inds, reg=1e-6):\n",
    "    \"\"\"\n",
    "    Use X, Y, Z to estimate the Rel-UME power criterion function and evaluate\n",
    "    the function at each point (individually) in loc_pool (2d numpy array).\n",
    "    \n",
    "    * k: a kernel\n",
    "    * func_inds: list of indices of the functions to evaluate. See below.\n",
    "    * reg: regularization parameter in the power criterion\n",
    "    \n",
    "    Return an m x (up to) 5 numpy array where m = number of candidates in the\n",
    "    pool. The columns can be (as specified in func_inds): \n",
    "        0. power criterion\n",
    "        1. evaluation of the relative witness\n",
    "        2. evaluation of MMD witness(p, r) (not squared)\n",
    "        3. evaluation of witness(q, r)\n",
    "        4. evaluate of witness(p, q)\n",
    "        \n",
    "    \"\"\"\n",
    "    datap = data.Data(X)\n",
    "    dataq = data.Data(Y)\n",
    "    datar = data.Data(Z)\n",
    "\n",
    "    powcri_func = mct.SC_UME.get_power_criterion_func(datap, dataq, datar, k, k, reg=1e-7)\n",
    "    relwit_func = mct.SC_UME.get_relative_sqwitness(datap, dataq, datar, k, k)\n",
    "    witpr = tst.MMDWitness(k, X, Z)\n",
    "    witqr = tst.MMDWitness(k, Y, Z)\n",
    "    witpq = tst.MMDWitness(k, X, Y)\n",
    "    \n",
    "    funcs = [powcri_func, relwit_func, witpr, witqr, witpq]\n",
    "    # select the functions according to func_inds\n",
    "    list_evals = [funcs[i](loc_pool) for i in func_inds]\n",
    "    stack_evals = np.vstack(list_evals)\n",
    "    return stack_evals.T\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gaussian kernel with median heuristic\n",
    "medxz = util.meddistance(np.vstack((X, Z)), subsample=1000)\n",
    "medyz = util.meddistance(np.vstack((Y, Z)), subsample=1000)\n",
    "k = kernel.KGauss(np.mean([medxz, medyz])**2)\n",
    "print('Gaussian width: {}'.format(k.sigma2**0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram. This will take some time.\n",
    "func_inds = np.array([0, 1, 4])\n",
    "pool_evals = eval_test_locations(X, Y, Z, loc_pool=pool, k=k, func_inds=func_inds, reg=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pow_cri_values = pool_evals[:, func_inds==0].reshape(-1)\n",
    "rel_wit_values = pool_evals[:, func_inds==1].reshape(-1)\n",
    "witpq_values = pool_evals[:, func_inds==4].reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the histogram\n",
    "plt.figure(figsize=(8, 5))\n",
    "a = 0.6\n",
    "plt.hist(pow_cri_values, label='Pow. Cri.', alpha=a);\n",
    "plt.hist(witpq_values, label='wit(p,q)', alpha=a);\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(rel_wit_values, label='Rel. Wit', alpha=a);\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_3c_rescale(img_in_stack):\n",
    "    img = img_in_stack.reshape([3, 32, 32])\n",
    "    # h x w x c\n",
    "    img = img.transpose([1, 2, 0])/255.0\n",
    "    return img\n",
    "\n",
    "def plot_lowzerohigh(images, values, text_in_title='', grid_rows=2,\n",
    "        grid_cols=10, figsize=(13, 3)):\n",
    "    \"\"\"\n",
    "    Sort the values in three different ways (ascending, descending, absolute ascending).\n",
    "    Plot the images corresponding to the top-k sorted values. k is determined\n",
    "    by the grid size.\n",
    "    \"\"\"\n",
    "    low_inds, zeros_inds, high_inds = util.top_lowzerohigh(values)\n",
    "    \n",
    "    plt.figure(figsize=figsize)\n",
    "    exu.plot_images_grid(images[low_inds], reshape_3c_rescale, grid_rows, grid_cols)\n",
    "    plt.suptitle('{} Low'.format(text_in_title))\n",
    "    \n",
    "    plt.figure(figsize=figsize)\n",
    "    exu.plot_images_grid(images[zeros_inds], reshape_3c_rescale, grid_rows, grid_cols)\n",
    "    plt.suptitle('{} Near Zero'.format(text_in_title))\n",
    "    \n",
    "    plt.figure(figsize=figsize)\n",
    "    exu.plot_images_grid(images[high_inds], reshape_3c_rescale, grid_rows, grid_cols)\n",
    "    plt.suptitle('{} High'.format(text_in_title))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_rows = 1\n",
    "grid_cols = 10\n",
    "figsize = (12, 2)\n",
    "plot_lowzerohigh(poolimgs, pow_cri_values, 'Power Criterion.', grid_rows, grid_cols, figsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_lowzerohigh(poolimgs, rel_wit_values, 'Relative Witness.', grid_rows, grid_cols, figsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
